{% extends "base.html" %}

{% block title %}ƒêƒÉng k√Ω - Face Recognition System{% endblock %}

{% block content %}
<div class="card">
    <div class="card-header">üìù ƒêƒÉng k√Ω ng∆∞·ªùi d√πng m·ªõi (10 ·∫£nh)</div>

    <div id="alertContainer"></div>

    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin-top: 1.5rem;">
        <!-- Camera Preview -->
        <div>
            <h3 style="margin-bottom: 1rem;">üì∑ Ch·ª•p 10 ·∫£nh khu√¥n m·∫∑t</h3>
            <div class="video-container" style="position: relative;">
                <!-- Video & Canvas: Mirrored -->
                <video id="video" autoplay playsinline style="transform: scaleX(-1);"></video>
                <canvas id="canvas" style="transform: scaleX(-1);"></canvas>

                <!-- Status Overlay (Not mirrored) -->
                <div id="statusText" style="
                    position: absolute; 
                    top: 20px; 
                    left: 0; 
                    width: 100%; 
                    text-align: center; 
                    color: white; 
                    font-weight: bold; 
                    font-size: 24px; 
                    text-shadow: 2px 2px 4px #000; 
                    z-index: 10;
                    pointer-events: none;
                "></div>
            </div>

            <!-- Progress bar -->
            <div class="progress-container" style="margin-top: 1rem;">
                <div class="progress-bar">
                    <div class="progress-fill" id="progressFill" style="width: 0%"></div>
                </div>
                <div class="progress-text">
                    <span id="captureCount">0</span> / 10 ·∫£nh
                </div>
            </div>

            <!-- Capture instructions -->
            <div id="instructions" class="instructions">
                <h4>üìã H∆∞·ªõng d·∫´n ch·ª•p ·∫£nh:</h4>
                <li id="step1" class="active">1. Nh√¨n th·∫≥ng v√†o camera (10 ·∫£nh)</li>
                </ul>
            </div>

            <div style="display: flex; gap: 1rem; margin-top: 1rem;">
                <button id="startCaptureBtn" class="btn btn-primary" style="flex: 1;" disabled>
                    ‚è≥ ƒêang t·∫£i AI...
                </button>
                <button id="stopCaptureBtn" class="btn btn-danger" style="flex: 1;" disabled>
                    ‚è∏Ô∏è D·ª´ng
                </button>
            </div>

            <button id="resetBtn" class="btn btn-secondary" style="width: 100%; margin-top: 0.5rem;">
                üîÑ Ch·ª•p l·∫°i t·ª´ ƒë·∫ßu
            </button>
        </div>

        <!-- Registration Form -->
        <div>
            <h3 style="margin-bottom: 1rem;">‚ÑπÔ∏è Th√¥ng tin ng∆∞·ªùi d√πng</h3>
            <form id="registerForm">
                <div class="form-group">
                    <label for="name">H·ªç v√† t√™n *</label>
                    <input type="text" id="name" name="name" required placeholder="Nh·∫≠p h·ªç v√† t√™n">
                </div>

                <div class="form-group">
                    <label for="userId">M√£ s·ªë *</label>
                    <input type="text" id="userId" name="userId" required placeholder="Nh·∫≠p m√£ s·ªë (ID)">
                </div>

                <div class="form-group">
                    <label>·∫¢nh ƒë√£ ch·ª•p</label>
                    <div id="capturedImagesContainer" class="captured-grid">
                        <p style="color: var(--text-muted); font-style: italic; grid-column: span 5;">
                            Ch∆∞a ch·ª•p ·∫£nh. Nh·∫•n "B·∫Øt ƒë·∫ßu" ƒë·ªÉ th·ª±c hi·ªán theo h∆∞·ªõng d·∫´n.
                        </p>
                    </div>
                </div>

                <button type="submit" id="submitBtn" class="btn btn-success" style="width: 100%;" disabled>
                    ‚úÖ ƒêƒÉng k√Ω (c·∫ßn ƒë·ªß 10 ·∫£nh)
                </button>
            </form>
        </div>
    </div>
</div>

<style>
    /* Mirror logic */
    /* video,
    canvas {
        transform: scaleX(-1);
    } */

    #canvas {
        position: absolute;
        top: 0;
        left: 0;
        pointer-events: none;
    }

    .progress-container {
        border-radius: 8px;
        padding: 1rem;
        background: rgba(255, 255, 255, 0.05);
    }

    .progress-bar {
        background: var(--dark);
        border-radius: 4px;
        height: 20px;
        overflow: hidden;
    }

    .progress-fill {
        background: linear-gradient(135deg, var(--primary), var(--secondary));
        height: 100%;
        transition: width 0.3s ease;
        border-radius: 4px;
    }

    .progress-text {
        text-align: center;
        margin-top: 0.5rem;
        font-weight: 600;
        color: var(--text);
    }

    .instructions {
        background: rgba(255, 255, 255, 0.05);
        border-radius: 8px;
        padding: 1rem;
        margin-top: 1rem;
    }

    .instructions h4 {
        margin-bottom: 0.75rem;
        color: var(--primary);
    }

    .instructions ul {
        list-style: none;
        padding: 0;
    }

    .instructions li {
        padding: 0.5rem;
        border-radius: 4px;
        margin-bottom: 0.25rem;
        color: var(--text-muted);
        transition: all 0.3s ease;
        border-left: 3px solid transparent;
    }

    .instructions li.active {
        background: rgba(99, 102, 241, 0.1);
        color: var(--primary);
        font-weight: 600;
        border-left-color: var(--primary);
    }

    .instructions li.done {
        background: rgba(16, 185, 129, 0.1);
        color: var(--success);
        border-left-color: var(--success);
        text-decoration: line-through;
    }

    .captured-grid {
        display: grid;
        grid-template-columns: repeat(5, 1fr);
        gap: 0.5rem;
        max-height: 300px;
        overflow-y: auto;
        padding: 0.5rem;
        background: rgba(255, 255, 255, 0.05);
        border-radius: 8px;
    }

    .captured-grid img {
        width: 100%;
        aspect-ratio: 1;
        object-fit: cover;
        border-radius: 4px;
        border: 2px solid var(--border);
    }

    .captured-grid img.valid {
        border-color: var(--success);
    }

    .captured-grid img.invalid {
        border-color: var(--danger);
    }

    .btn-secondary {
        background: var(--dark-lighter);
        color: var(--text);
        border: 1px solid var(--border);
    }

    .btn-secondary:hover {
        background: var(--dark-light);
    }
</style>
{% endblock %}

{% block scripts %}
<script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const statusText = document.getElementById('statusText');
    const startCaptureBtn = document.getElementById('startCaptureBtn');
    const stopCaptureBtn = document.getElementById('stopCaptureBtn');
    const resetBtn = document.getElementById('resetBtn');
    const submitBtn = document.getElementById('submitBtn');
    const registerForm = document.getElementById('registerForm');
    const alertContainer = document.getElementById('alertContainer');
    const capturedImagesContainer = document.getElementById('capturedImagesContainer');
    const progressFill = document.getElementById('progressFill');
    const captureCountSpan = document.getElementById('captureCount');

    // Configuration
    const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
    const TARGET_IMAGES = 10;
    const CAPTURE_COOLDOWN = 800; // ms

    // State
    let stream = null;
    let capturedImages = [];
    let isCapturing = false;
    let isModelLoaded = false;
    let detectionsLoop = null;
    let lastCaptureTime = 0;

    const STEPS = [
        { id: 'step1', name: 'straight', instruction: 'Gi·ªØ ƒë·∫ßu th·∫≥ng v√† nh√¨n v√†o camera', range: [0, 10] }
    ];

    function showAlert(message, type = 'info') {
        const alertDiv = document.createElement('div');
        alertDiv.className = `alert alert-${type}`;
        alertDiv.textContent = message;
        alertContainer.innerHTML = '';
        alertContainer.appendChild(alertDiv);
        setTimeout(() => alertDiv.remove(), 5000);
    }

    async function loadModels() {
        startCaptureBtn.disabled = true;
        startCaptureBtn.textContent = '‚è≥ ƒêang t·∫£i AI...';
        setStatus("‚è≥ ƒêang t·∫£i m√¥ h√¨nh AI...", "white");
        try {
            await Promise.all([
                faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
                faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL)
            ]);
            isModelLoaded = true;
            startCaptureBtn.disabled = false;
            startCaptureBtn.textContent = '‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu ch·ª•p t·ª± ƒë·ªông';
            setStatus("‚úÖ AI S·∫µn s√†ng! Nh·∫•n B·∫Øt ƒë·∫ßu.", "#10b981");
        } catch (error) {
            console.error(error);
            setStatus("‚ùå L·ªói t·∫£i AI", "red");
        }
    }

    function getHeadPose(landmarks) {
        const nose = landmarks.getNose()[3];
        const jaw = landmarks.getJawOutline();
        const leftEye = landmarks.getLeftEye();
        const rightEye = landmarks.getRightEye();
        const mouth = landmarks.getMouth();

        // Yaw Calculation (Raw Video Data)
        // Note: FaceAPI processes typical Webcam stream as Raw (non-mirrored)
        // Turn LEFT -> Nose moves to Image Right -> Yaw Ratio Increases
        // Turn RIGHT -> Nose moves to Image Left -> Yaw Ratio Decreases

        const jawLeft = jaw[0];
        const jawRight = jaw[16];
        const faceWidth = jawRight.x - jawLeft.x;
        const noseDistToImageLeft = nose.x - jawLeft.x;
        const yawRatio = noseDistToImageLeft / faceWidth;

        // Thresholds
        // Center ~ 0.5
        // < 0.45: Nose is left -> User turned RIGHT
        // > 0.55: Nose is right -> User turned LEFT

        let yaw = 'center';
        if (yawRatio < 0.45) yaw = 'user_right';
        else if (yawRatio > 0.55) yaw = 'user_left';

        // Pitch Calculation
        const avgEyeY = (leftEye.reduce((a, b) => a + b.y, 0) + rightEye.reduce((a, b) => a + b.y, 0)) / 12;
        const avgMouthY = mouth.reduce((a, b) => a + b.y, 0) / 20;
        const noseY = nose.y;

        const faceHeight = avgMouthY - avgEyeY;
        const noseDist = noseY - avgEyeY;
        const pitchRatio = noseDist / faceHeight;

        let pitch = 'center';
        if (pitchRatio < 0.35) pitch = 'up';
        else if (pitchRatio > 0.65) pitch = 'down';

        return { yaw, pitch };
    }

    async function onPlay() {
        if (video.paused || video.ended || !isModelLoaded) return setTimeout(() => onPlay(), 100);

        const displaySize = { width: video.videoWidth, height: video.videoHeight };
        faceapi.matchDimensions(canvas, displaySize);

        detectionsLoop = setInterval(async () => {
            const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            if (detections) {
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                faceapi.draw.drawFaceLandmarks(canvas, resizedDetections, {
                    drawLines: true,
                    color: 'rgba(0, 255, 255, 0.5)'
                });

                if (isCapturing && capturedImages.length < TARGET_IMAGES) {
                    processValidation(resizedDetections);
                }
            } else if (isCapturing) {
                setStatus("‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t", "red");
            }
        }, 100);
    }

    function setStatus(text, color) {
        statusText.textContent = text;
        statusText.style.color = color;
    }

    function processValidation(detection) {
        const count = capturedImages.length;
        let currentStep = STEPS[0];
        for (const step of STEPS) {
            if (count >= step.range[0] && count < step.range[1]) {
                currentStep = step;
                break;
            }
        }

        const pose = getHeadPose(detection.landmarks);
        let isValid = false;
        let message = currentStep.instruction;

        // Check if looking straight
        if (pose.yaw === 'center' && pose.pitch === 'center') {
            isValid = true;
        } else {
            message = "H√£y nh√¨n th·∫≥ng v√†o camera!";
        }

        if (isValid) {
            setStatus("‚úÖ OK! Gi·ªØ nguy√™n...", "#10b981");
            const now = Date.now();
            if (now - lastCaptureTime > CAPTURE_COOLDOWN) {
                captureImage();
                lastCaptureTime = now;
            }
        } else {
            setStatus("‚ö†Ô∏è " + message, "#f59e0b");
        }
        highlightStep(currentStep.id);
    }

    function highlightStep(stepId) {
        STEPS.forEach(s => {
            const el = document.getElementById(s.id);
            if (el.id === stepId) {
                el.classList.add('active');
                el.classList.remove('done');
            } else {
                el.classList.remove('active');
                if (capturedImages.length >= s.range[1]) el.classList.add('done');
            }
        });
    }

    async function startCamera() {
        try {
            stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
            video.srcObject = stream;
            video.addEventListener('play', onPlay);
            loadModels();
        } catch (error) {
            setStatus("L·ªói Camera", "red");
        }
    }

    function captureImage() {
        if (capturedImages.length >= TARGET_IMAGES) return;
        const captureCanvas = document.createElement('canvas');
        captureCanvas.width = video.videoWidth;
        captureCanvas.height = video.videoHeight;
        const ctx = captureCanvas.getContext('2d');
        ctx.drawImage(video, 0, 0);
        const dataUrl = captureCanvas.toDataURL('image/jpeg', 0.85);

        capturedImages.push(dataUrl);
        addCapturedImage(dataUrl, true);
        updateProgress();

        if (capturedImages.length >= TARGET_IMAGES) finishCapture();
    }

    function addCapturedImage(dataUrl, isValid) {
        const img = document.createElement('img');
        img.src = dataUrl;
        img.className = isValid ? 'valid' : 'invalid';
        if (capturedImagesContainer.querySelector('p')) capturedImagesContainer.querySelector('p').remove();
        capturedImagesContainer.appendChild(img);
        capturedImagesContainer.scrollTop = capturedImagesContainer.scrollHeight;
    }

    function updateProgress() {
        const percent = (capturedImages.length / TARGET_IMAGES) * 100;
        progressFill.style.width = `${percent}%`;
        captureCountSpan.textContent = capturedImages.length;
    }

    function finishCapture() {
        isCapturing = false;
        startCaptureBtn.disabled = true;
        stopCaptureBtn.disabled = true;
        submitBtn.disabled = false;
        setStatus("üéâ Xong! H√£y b·∫•m ƒêƒÉng k√Ω.", "#10b981");
        if (detectionsLoop) clearInterval(detectionsLoop);
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);
    }

    function startCapture() {
        if (!isModelLoaded || capturedImages.length >= TARGET_IMAGES) return;
        isCapturing = true;
        startCaptureBtn.disabled = true;
        stopCaptureBtn.disabled = false;
        setStatus("üé¨ B·∫Øt ƒë·∫ßu...", "white");
    }

    function stopCapture() {
        isCapturing = false;
        startCaptureBtn.disabled = false;
        stopCaptureBtn.disabled = true;
        setStatus("ƒê√£ d·ª´ng", "white");
    }

    function resetCapture() {
        stopCapture();
        capturedImages = [];
        capturedImagesContainer.innerHTML = '<p style="color: var(--text-muted); font-style: italic; grid-column: span 5;">Ch∆∞a ch·ª•p ·∫£nh n√†o.</p>';
        updateProgress();
        highlightStep('step1');
        submitBtn.disabled = true;
        setStatus("S·∫µn s√†ng", "white");
    }

    startCaptureBtn.addEventListener('click', startCapture);
    stopCaptureBtn.addEventListener('click', stopCapture);
    resetBtn.addEventListener('click', resetCapture);

    registerForm.addEventListener('submit', async (e) => {
        e.preventDefault();
        if (capturedImages.length < TARGET_IMAGES) return showAlert('Ch∆∞a ƒë·ªß ·∫£nh', 'error');
        const name = document.getElementById('name').value;
        const userId = document.getElementById('userId').value;
        submitBtn.disabled = true;
        submitBtn.innerHTML = '‚è≥ ƒêang g·ª≠i...';

        try {
            const formData = new FormData();
            formData.append('name', name);
            formData.append('user_id', userId);
            formData.append('images', JSON.stringify(capturedImages));
            const response = await fetch('/api/register', { method: 'POST', body: formData });
            const data = await response.json();
            if (response.ok) {
                showAlert('‚úÖ Th√†nh c√¥ng!', 'success');
                setTimeout(() => window.location.href = '/', 1500);
            } else {
                showAlert('‚ùå ' + (data.detail || 'L·ªói'), 'error');
                submitBtn.disabled = false;
                submitBtn.textContent = '‚úÖ ƒêƒÉng k√Ω again';
            }
        } catch (e) {
            showAlert('L·ªói k·∫øt n·ªëi', 'error');
            submitBtn.disabled = false;
            submitBtn.textContent = '‚úÖ ƒêƒÉng k√Ω again';
        }
    });

    startCamera();
    window.addEventListener('beforeunload', () => {
        if (stream) stream.getTracks().forEach(t => t.stop());
        if (detectionsLoop) clearInterval(detectionsLoop);
    });
</script>
{% endblock %}